{
  "questions": [
    {"id": "1",  "namespace": "ckad-q01", "machineHostname": "ckad9999", "question": "List all namespaces and save output to /opt/course/exam3/q01/namespaces.", "concepts": ["namespaces"], "verification": [
      {"id": "1", "description": "Q1: namespaces file exists", "verificationScriptFile": "q1_s1_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q1: file contains default namespace", "verificationScriptFile": "q1_s3_validate_contains_default.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "2",  "namespace": "ckad-q02", "machineHostname": "ckad9999", "question": "Your task is to create a new Pod and a status script in the dedicated namespace for this question.\n\n**Instructions:**\n1.  **Create a Pod:**\n    *   Name the Pod: `pod1`\n    *   Use the image: `httpd:2.4.41-alpine`\n    *   Set the container name within the Pod to: `pod1-container`\n    *   Ensure this Pod is created in the `ckad-q02` namespace.\n2.  **Create a Status Script:**\n    *   Develop a command that outputs the current status (`.status.phase`) of the `pod1` Pod.\n    *   Save this command as an executable script file: `/opt/course/exam3/q02/pod1-status-command.sh`\n\n**Verification:**\n*   The Pod `pod1` must be running in the `ckad-q02` namespace.\n*   The `pod1-container` container must exist within the `pod1` Pod.\n*   The script file `/opt/course/exam3/q02/pod1-status-command.sh` must exist and be executable.", "concepts": ["pods"], "verification": [
      {"id": "1", "description": "Q2: pod pod1 exists", "verificationScriptFile": "q2_s1_validate_pod_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q2: container name is pod1-container", "verificationScriptFile": "q2_s2_validate_container_name.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q2: status script exists and is executable", "verificationScriptFile": "q2_s3_validate_status_script.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "3",  "namespace": "ckad-q03", "machineHostname": "ckad9999", "question": "Team Neptune needs a new Job. Your task is to create this Job according to the specifications below and save its configuration.\n\n**Instructions:**\n1.  **Create a Job:**\n    *   Name the Job: `neb-new-job`\n    *   Use the image: `busybox:1.31.0`\n    *   The command for the container should be: `sleep 2 && echo done`\n    *   Set `completions` to `3` (the Job should run to completion 3 times).\n    *   Set `parallelism` to `2` (a maximum of 2 Pods should run at any given time).\n    *   The container within the Job's Pods should be named: `neb-new-job-container`\n    *   Each Pod created by the Job should have the label: `id=awesome-job`\n    *   Ensure this Job is created in the `ckad-q03` namespace.\n2.  **Save Configuration:**\n    *   Save the YAML definition of the Job to the file: `/opt/course/exam3/q03/job.yaml`\n3.  **Deploy and Verify:**\n    *   Create the Job using your saved YAML file.\n    *   Verify that the Job eventually completes all 3 runs with a maximum of 2 parallel executions.\n\n**Verification:**\n*   The Job `neb-new-job` must exist and be running in the `ckad-q03` namespace.\n*   The Job's `completions` parameter must be set to `3`.\n*   The Job's `parallelism` parameter must be set to `2`.\n*   The Pods created by the Job must have the label `id=awesome-job`.\n*   The YAML definition of the Job must be saved to `/opt/course/exam3/q03/job.yaml`.", "concepts": ["jobs"], "verification": [
      {"id": "1", "description": "Q3: job exists", "verificationScriptFile": "q3_s1_validate_job_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q3: completions=3 and parallelism=2", "verificationScriptFile": "q3_s2_validate_job_spec.sh", "expectedOutput": "0", "weightage": 2},
      {"id": "3", "description": "Q3: job yaml file exists", "verificationScriptFile": "q3_s3_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "4",  "namespace": "ckad-q04", "machineHostname": "ckad9999", "question": "Team Mercury has asked you to perform several Helm operations within the `ckad-q04` namespace.\n\n**Pre-requisites:**\n*   Ensure the Helm repository `killershell` is added and updated:\n    ```bash\n    helm repo add killershell http://localhost:6000\n    helm repo update\n    ```\n\n**Instructions:**\n1.  **Delete a Release:** Delete the Helm release named `internal-issue-report-apiv1`.\n2.  **Upgrade a Release:** Upgrade the Helm release named `internal-issue-report-apiv2` to any newer version of the `killershell/nginx` chart.\n3.  **Install a New Release:** Install a new Helm release named `internal-issue-report-apache` using the `killershell/apache` chart. This Deployment should have `2 replicas`. Ensure you set the replica count via Helm values during installation.\n4.  **Clean Up Pending Releases:** Identify and delete any Helm releases that are stuck in a `pending-install` state.\n\n**Verification:**\n*   The `internal-issue-report-apiv1` release should no longer exist in the `ckad-q04` namespace.\n*   The `internal-issue-report-apiv2` release should be upgraded to a newer chart version.\n*   The `internal-issue-report-apache` release should be successfully installed with `2 replicas`.\n*   Any releases in a `pending-install` state should be removed.", "concepts": ["helm"], "verification": [
      {"id": "1", "description": "Q4: apiv1 not present", "verificationScriptFile": "q4_s1_validate_apiv1_absent.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q4: apiv2 present", "verificationScriptFile": "q4_s2_validate_apiv2_present.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q4: apache replicas=2", "verificationScriptFile": "q4_s3_validate_apache_replicas.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "5",  "namespace": "ckad-q05", "machineHostname": "ckad9999", "question": "Team Neptune requires assistance with a ServiceAccount and its associated Secret token within the `ckad-q05` namespace.\n\n**Instructions:**\n1.  **Locate ServiceAccount Token:**\n    *   An existing ServiceAccount named `neptune-sa-v2` is present in the `ckad-q05` namespace.\n    *   Identify the Secret that is automatically generated and associated with this ServiceAccount. This Secret contains the ServiceAccount's token.\n2.  **Extract and Decode Token:**\n    *   Retrieve the token from the identified Secret.\n    *   The token will be Base64 encoded. Decode this token.\n3.  **Save Decoded Token:**\n    *   Write the Base64 decoded token to the file: `/opt/course/exam3/q05/token` on the `localhost` instance.\n\n**Verification:**\n*   A file named `/opt/course/exam3/q05/token` must exist.\n*   The file `/opt/course/exam3/q05/token` must contain the Base64 decoded token and not be empty.", "concepts": ["serviceaccounts","secrets"], "verification": [
      {"id": "1", "description": "Q5: ServiceAccount exists", "verificationScriptFile": "q5_s1_validate_sa_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q5: token file exists and non-empty", "verificationScriptFile": "q5_s2_validate_token_file.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "6",  "namespace": "ckad-q06", "machineHostname": "ckad9999", "question": "Create pod6 with readinessProbe cat /tmp/ready and command to create it.", "concepts": ["probes","pods"], "verification": [
      {"id": "1", "description": "Q6: pod6 exists", "verificationScriptFile": "q6_s1_validate_pod_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q6: pod6 is Ready", "verificationScriptFile": "q6_s2_validate_pod_ready.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "7",  "namespace": "ckad-q07", "machineHostname": "ckad9999", "question": "A running Pod needs to be relocated between namespaces without changing its behavior. Perform the move by recreating the Pod in the target namespace and removing it from the source.\n\n**Scope:**\nAll actions must be performed on the single cluster, using the dedicated namespaces for this task.\n\n**Source State (already seeded):**\n* Namespace: `ckad-q07-source`\n* Pod Name: `webserver-sat-003`\n* Container Name: `webserver-sat`\n* Image: `nginx:1.16.1-alpine`\n* Labels: `id=webserver-sat-003`\n* Annotation: `description="this is the server for the E-Commerce System my-happy-shop"`\n\n**Target State (what you must achieve):**\n* Namespace: `ckad-q07-target`\n* A Pod named `webserver-sat-003` exists and is Running.\n* The Pod preserves the same container name, image, labels, and annotations as the source Pod.\n* The Pod no longer exists in `ckad-q07-source`.\n\n**Task:**\n1. Re-create the Pod `webserver-sat-003` in namespace `ckad-q07-target` with the exact same spec (container name, image, labels, and annotations).\n2. Remove the original Pod from `ckad-q07-source`.\n3. Save the final manifest you used for the target Pod to `/opt/course/exam3/q07/webserver-sat-003.yaml`.\n\n**Notes and Hints:**\n* You cannot literally "move" a Pod between namespaces; re-create it in the new namespace.\n* A practical approach is to export the source Pod spec, adjust only the `metadata.namespace`, and apply it in the target: for example, `kubectl -n ckad-q07-source get pod webserver-sat-003 -o yaml > /opt/course/exam3/q07/webserver-sat-003.yaml`, then edit the file and `kubectl -n ckad-q07-target apply -f /opt/course/exam3/q07/webserver-sat-003.yaml`. Finally, delete the source Pod.\n\n**Verification:**\n* The Pod `webserver-sat-003` is absent from `ckad-q07-source`.\n* The Pod `webserver-sat-003` exists in `ckad-q07-target`.\n", "concepts": ["pods","namespaces"], "verification": [
      {"id": "1", "description": "Q7: pod not in source", "verificationScriptFile": "q7_s1_validate_absent_in_source.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q7: pod in target", "verificationScriptFile": "q7_s2_validate_present_in_target.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "8",  "namespace": "ckad-q08", "machineHostname": "ckad9999", "question": "Rollback deployment api-new-c32 to a working revision after bad rollout.", "concepts": ["deployments","rollouts"], "verification": [
      {"id": "1", "description": "Q8: deployment exists", "verificationScriptFile": "q8_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q8: deployment ready", "verificationScriptFile": "q8_s2_validate_deploy_ready.sh", "expectedOutput": "0", "weightage": 3}
    ]},
    {"id": "9",  "namespace": "ckad-q09", "machineHostname": "ckad9999", "question": "Convert Pod holy-api into a Deployment with 3 replicas; save YAML to /opt/course/exam3/q09/holy-api-deployment.yaml.", "concepts": ["deployments","security"], "verification": [
      {"id": "1", "description": "Q9: deployment exists", "verificationScriptFile": "q9_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q9: replicas=3", "verificationScriptFile": "q9_s2_validate_replicas.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q9: YAML file exists", "verificationScriptFile": "q9_s3_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "10", "namespace": "ckad-q10", "machineHostname": "ckad9999", "question": "Create ClusterIP service project-plt-6cc-svc for pod project-plt-6cc-api (port 3333→80); save curl output to file.", "concepts": ["services","pods","logs"], "verification": [
      {"id": "1", "description": "Q10: service 3333→80 mapping", "verificationScriptFile": "q10_s1_validate_service_ports.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q10: pod exists", "verificationScriptFile": "q10_s2_validate_pod_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q10: output file exists", "verificationScriptFile": "q10_s3_validate_output_file.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "11", "namespace": "ckad-q11", "machineHostname": "ckad9999", "question": "Build/push images (docker & podman) with ENV SUN_CIPHER_ID; write container logs to /opt/course/exam3/q11/logs.", "concepts": ["images","containers"], "verification": [
      {"id": "1", "description": "Q11: logs file exists", "verificationScriptFile": "q11_s1_validate_logs_file.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q11: logs contain SUN_CIPHER_ID", "verificationScriptFile": "q11_s2_validate_logs_content.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "12", "namespace": "ckad-q12", "machineHostname": "ckad9999", "question": "Create PV/PVC and deployment mounting at /tmp/project-data.", "concepts": ["storage","pv","pvc","deployments"], "verification": [
      {"id": "1", "description": "Q12: PV exists", "verificationScriptFile": "q12_s1_validate_pv_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q12: PVC exists", "verificationScriptFile": "q12_s2_validate_pvc_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q12: PVC is Bound", "verificationScriptFile": "q12_s3_validate_pvc_bound.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "4", "description": "Q12: deployment exists", "verificationScriptFile": "q12_s4_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "13", "namespace": "ckad-q13", "machineHostname": "ckad9999", "question": "Create StorageClass moon-retain and PVC moon-pvc-126; PVC Pending and reason written.", "concepts": ["storageclass","pvc"], "verification": [
      {"id": "1", "description": "Q13: StorageClass exists", "verificationScriptFile": "q13_s1_validate_sc_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q13: PVC exists", "verificationScriptFile": "q13_s2_validate_pvc_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q13: PVC is Pending", "verificationScriptFile": "q13_s3_validate_pvc_pending.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "4", "description": "Q13: reason file exists", "verificationScriptFile": "q13_s4_validate_reason_file.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "14", "namespace": "ckad-q14", "machineHostname": "ckad9999", "question": "Pod secret-handler uses secret1 env and secret2 (configmap) volume; save updated YAML.", "concepts": ["secrets","pods"], "verification": [
      {"id": "1", "description": "Q14: secret1 exists", "verificationScriptFile": "q14_s1_validate_secret_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q14: pod secret-handler exists", "verificationScriptFile": "q14_s2_validate_pod_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "Q14: updated YAML exists", "verificationScriptFile": "q14_s3_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "15", "namespace": "ckad-q15", "machineHostname": "ckad9999", "question": "Create ConfigMap configmap-web-moon-html from file and validate deployment usage.", "concepts": ["configmaps","deployments"], "verification": [
      {"id": "1", "description": "Q15: ConfigMap exists", "verificationScriptFile": "q15_s1_validate_configmap_exists.sh", "expectedOutput": "0", "weightage": 2},
      {"id": "2", "description": "Q15: configmap.yaml exists", "verificationScriptFile": "q15_s2_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "16", "namespace": "ckad-q16", "machineHostname": "ckad9999", "question": "Add logging sidecar to cleaner and save updated YAML.", "concepts": ["logging","sidecar"], "verification": [
      {"id": "1", "description": "Q16: deployment exists", "verificationScriptFile": "q16_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q16: cleaner-new.yaml exists", "verificationScriptFile": "q16_s2_validate_file_exists.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "17", "namespace": "ckad-q17", "machineHostname": "ckad9999", "question": "Add initContainer and save updated YAML.", "concepts": ["initcontainers","volumes"], "verification": [
      {"id": "1", "description": "Q17: deployment exists", "verificationScriptFile": "q17_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q17: test-init-container-new.yaml exists", "verificationScriptFile": "q17_s2_validate_file_exists.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "18", "namespace": "ckad-q18", "machineHostname": "ckad9999", "question": "Fix misconfigured service manager-api-svc→deployment manager-api-deployment; endpoints present.", "concepts": ["services","selectors"], "verification": [
      {"id": "1", "description": "Q18: service exists", "verificationScriptFile": "q18_s1_validate_service_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q18: service has endpoints", "verificationScriptFile": "q18_s2_validate_endpoints.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "19", "namespace": "ckad-q19", "machineHostname": "ckad9999", "question": "Change ClusterIP service jupiter-crew-svc to NodePort 30100 and test reachability.", "concepts": ["services","nodeport"], "verification": [
      {"id": "1", "description": "Q19: service is NodePort", "verificationScriptFile": "q19_s1_validate_type_nodeport.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "Q19: nodePort=30100", "verificationScriptFile": "q19_s2_validate_nodeport_value.sh", "expectedOutput": "0", "weightage": 2}
    ]},
    {"id": "20", "namespace": "ckad-p1",  "machineHostname": "ckad9999", "question": "Add TCP livenessProbe to project-23-api; save updated YAML.", "concepts": ["probes","deployments"], "verification": [
      {"id": "1", "description": "P1: deployment exists", "verificationScriptFile": "q20_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "P1: updated YAML exists", "verificationScriptFile": "q20_s2_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "21", "namespace": "ckad-p2",  "machineHostname": "ckad9999", "question": "Create sunny (4 replicas) using SA sa-sun-deploy; expose sun-srv:9999; add status script.", "concepts": ["deployments","serviceaccounts","services"], "verification": [
      {"id": "1", "description": "P2: deployment exists", "verificationScriptFile": "q21_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "P2: replicas=4", "verificationScriptFile": "q21_s2_validate_replicas.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "P2: service sun-srv exists", "verificationScriptFile": "q21_s3_validate_service_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "4", "description": "P2: status script exists", "verificationScriptFile": "q21_s4_validate_status_script.sh", "expectedOutput": "0", "weightage": 1}
    ]},
    {"id": "22", "namespace": "ckad-p3",  "machineHostname": "ckad9999", "question": "Fix readinessProbe port on earth-3cc-web; write issue description.", "concepts": ["probes","services"], "verification": [
      {"id": "1", "description": "P3: deployment exists", "verificationScriptFile": "q22_s1_validate_deploy_exists.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "2", "description": "P3: deployment ready (all replicas)", "verificationScriptFile": "q22_s2_validate_deploy_ready.sh", "expectedOutput": "0", "weightage": 1},
      {"id": "3", "description": "P3: ticket-description.txt exists", "verificationScriptFile": "q22_s3_validate_file_exists.sh", "expectedOutput": "0", "weightage": 1}
    ]}
  ]
}
